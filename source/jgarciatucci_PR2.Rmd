---
title: 'PRA2 - Proyecto de minería de datos - Breast Cancer Wisconsin (Diagnostic)'
author: "Autor: Jose Luis Garcia Tucci - DNI. 49420791R"
date: "JUNIO 2023"
subtitle: "<span  style='background-color:#fbf8e4; display: block;font-size: 15px;padding: 0.5em'><b>Se incluye la Práctica 1 por continuidad en la narrativa del documento</b></span>"
output:
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 3
    includes:
      in_header: 75.584-PEC-header.html
toc-title: 'Tabla de contenidos'
header-includes:
  - \usepackage[fleqn]{amsmath}
---


``` {css, echo=FALSE, results='asis'}
body {background-color:#FFFFFF;}
h1.title {background-color: #74edfe; padding: 0.5em; color: #000078;font-weight: bold; font-size: 35px;}
.headers h1 {background-color: #74edfe; padding: 0.5em; color: #000078;font-weight: bold; font-size: 25px;}
.headers h2 {background-color: #74edfe; padding: 0.5em; color: #000078;font-weight: bold; font-size: 20px;}
.headers h3 {background-color: #74edfe; padding: 0.5em; color: #000078;font-size: 20px;}
.headers h4 {background-color: #ddebf7; padding: 0.5em; color: #000078;font-size: 20px;}
p {background-color: #F8F8F8; padding: 0.5em;text-indent: 15px}
)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Práctica 1 "Selección y preparación de un juego de datos" {.headers} 
******

## Planteamiento del problema {.headers} 


El cáncer de mama es una de las formas más comunes de cáncer en todo el mundo y representa un grave problema de salud pública. Cada año, se diagnostican millones de casos nuevos, y a pesar de los avances significativos en el diagnóstico y el tratamiento, la enfermedad sigue siendo una causa importante de mortalidad entre las mujeres.

Este proyecto se centra en el análisis de un conjunto de datos del "Breast Cancer Wisconsin (Diagnostic)" disponible en el repositorio UCI Machine Learning (https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29). Este conjunto de datos incluye características calculadas a partir de imágenes digitalizadas de aspiración con aguja fina (FNA) de masas mamarias. Las características describen las propiedades de los núcleos celulares presentes en las imágenes, lo que puede proporcionar una valiosa información para el diagnóstico del cáncer de mama.

El objetivo principal de este estudio es utilizar técnicas de minería de datos y aprendizaje automático para desarrollar un modelo predictivo que pueda clasificar con precisión si un tumor de mama es benigno o maligno basándose en estas características. Este modelo podría tener una serie de aplicaciones potenciales, desde ayudar a los médicos a tomar decisiones informadas hasta desarrollar sistemas de apoyo a la decisión en medicina.

Además de este objetivo principal, también exploraremos los datos para identificar patrones y relaciones que puedan proporcionar una mayor comprensión de la naturaleza del cáncer de mama. En concreto, realizaremos un análisis exploratorio de datos, preprocesamiento y limpieza de los datos, discretización de variables, análisis de componentes principales y finalmente, construiremos y evaluaremos nuestro modelo predictivo.

Al final de este estudio, esperamos no sólo haber desarrollado un modelo predictivo eficaz, sino también haber obtenido una visión más profunda de las características que influyen en el diagnóstico del cáncer de mama.

## Justificación de la Selección del Conjunto de Datos {.headers}

El conjunto de datos "Breast Cancer Wisconsin (Diagnostic)" es ideal para este proyecto debido a su relevancia clínica, alta calidad y diversidad de variables. El cáncer de mama es una de las principales causas de muerte en mujeres a nivel mundial, por lo que la creación de modelos predictivos para su diagnóstico tiene un impacto social significativo.

Este conjunto de datos, con 569 observaciones y una variedad de características de los núcleos celulares, ofrece la oportunidad de aplicar diversas técnicas de minería de datos, como el preprocesamiento de datos, el análisis exploratorio, la discretización y la reducción de la dimensionalidad. Por lo tanto, este conjunto de datos no solo está alineado con los objetivos del proyecto, sino que también es manejable en términos de tamaño y complejidad, lo que facilita el desarrollo y la evaluación de los modelos predictivos.

## Descripción general de los datos {.headers}

El conjunto de datos "Breast Cancer Wisconsin (Diagnostic)" contiene 569 registros, cada uno con 32 atributos. Cada registro representa una imagen digital de una aspiración con aguja fina (FNA) de una masa mamaria. Las características están calculadas a partir de una imagen digitalizada de una FNA y describen características de los núcleos celulares presentes en la imagen.

Los atributos incluyen un identificador único para cada imagen, el diagnóstico (maligno o benigno), y 30 características reales-valued que son medidas obtenidas a partir de la imagen. Estas características son el radio, la textura, el perímetro, el área, la suavidad, la compactación, la concavidad, los puntos cóncavos, la simetría y la dimensión fractal, cada una con su media, error estándar y el peor (o mayor) valor registrado.

En términos de los requisitos del proyecto, el conjunto de datos cumple con todos los criterios: tiene más de 500 observaciones, al menos 5 variables numéricas, 2 categóricas y 1 binaria.

Para cumplir con el requisito de dos variables categóricas, podemos discretizar dos de las variables numéricas. Las variables que pueden ser discretizadas pueden ser elegidas después de una cuidadosa exploración y análisis de los datos. Un ejemplo podría ser la discretización de las variables "radius_mean" y "texture_mean" en categorías como "bajo", "medio" y "alto" basado en sus respectivos terciles. El proceso de discretización se llevará a cabo durante el preprocesamiento y el análisis de los datos, utilizando técnicas apropiadas como la binarización y el corte de intervalos en R.

La razón por la que cada característica aparece tres veces en el conjunto de datos es porque para cada característica, el conjunto de datos incluye:

➤ El valor medio de la característica calculada a partir de la imagen.

➤El error estándar de la característica calculada a partir de la imagen.

➤ El "peor" o mayor valor de la característica calculado a partir de la imagen.

Por lo tanto, para cada característica, tienes tres medidas diferentes: la media, el error estándar y el peor valor. Esto proporciona una descripción más completa de la variabilidad de cada característica en la imagen de la masa mamaria.

El "peor" valor se calcula tomando el promedio de los tres valores más grandes de esa característica en particular.

Los atributos son los siguientes:

| Attribute | Description | Data Type |
| :--- | :--- | :---: |
| id | Identification number | Integer |
| diagnosis | Diagnosis (M = malignant, B = benign) | Categorical |
| radius_mean | Mean of distances from center to points on the perimeter | Numerical |
| texture_mean | Standard deviation of gray-scale values | Numerical |
| perimeter_mean | Mean of perimeter | Numerical |
| area_mean | Mean of area | Numerical |
| smoothness_mean | Local variation in radius lengths | Numerical |
| compactness_mean | Perimeter^2 / area - 1.0 | Numerical |
| concavity_mean | Severity of concave portions of the contour | Numerical |
| concave points_mean | Number of concave portions of the contour | Numerical |
| symmetry_mean | Mean of symmetry | Numerical |
| fractal_dimension_mean | "Coastline approximation" - 1 | Numerical |
| radius_se | Standard error for the mean of distances from center to points on the perimeter | Numerical |
| texture_se | Standard error for the standard deviation of gray-scale values | Numerical |
| perimeter_se | Standard error for the mean of perimeter | Numerical |
| area_se | Standard error for the mean of area | Numerical |
| smoothness_se | Standard error for the local variation in radius lengths | Numerical |
| compactness_se | Standard error for the perimeter^2 / area - 1.0 | Numerical |
| concavity_se | Standard error for the severity of concave portions of the contour | Numerical |
| concave points_se | Standard error for the number of concave portions of the contour | Numerical |
| symmetry_se | Standard error for the mean of symmetry | Numerical |
| fractal_dimension_se | Standard error for the "coastline approximation" - 1 | Numerical |
| radius_worst | Worst or largest mean value for the mean of distances from center to points on the perimeter | Numerical |
| texture_worst | Worst or largest mean value for the standard deviation of gray-scale values | Numerical |
| perimeter_worst | Worst or largest mean value for the mean of perimeter | Numerical |
| area_worst | Worst or largest mean value for the mean of area | Numerical |
| smoothness_worst | Worst or largest mean value for the local variation in radius lengths | Numerical |
| compactness_worst | Worst or largest mean value for the perimeter^2 / area - 1.0 | Numerical |
| concavity_worst | Worst or largest mean value for the severity of concave portions of the contour | Numerical |
| concave points_worst | Worst or largest mean value for the number of concave portions of the contour | Numerical |
| symmetry_worst | Worst or largest mean value for the mean of symmetry | Numerical |
| fractal_dimension_worst | Worst or largest mean value for the "coastline approximation" - 1 | Numerical |
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>


## Objetivos Analíticos {.headers}

Siguiendo la metodología CRISP-DM, los objetivos de este análisis son múltiples y se alinean con las etapas de este proceso estándar para la minería de datos.

Primero, en la etapa de comprensión del negocio, el objetivo es entender el dominio del cáncer de mama y la importancia del diagnóstico preciso. Esto incluye entender cómo se obtienen y se miden las características en las imágenes de las células del núcleo y cómo estas características pueden estar relacionadas con el diagnóstico de benignidad o malignidad.

En la etapa de comprensión de los datos, el objetivo es explorar y familiarizarse con el conjunto de datos de "Breast Cancer Wisconsin (Diagnostic)", comprendiendo la distribución, la relación y la calidad de los datos.

Para la etapa de preparación de los datos, el objetivo es limpiar y transformar los datos para su análisis. Esto incluirá la discretización de las variables para crear dos nuevas variables categóricas, tal como se requiere en el proyecto.

En la etapa de modelado, el objetivo es construir y evaluar varios modelos de aprendizaje supervisado para predecir el diagnóstico basado en las características de las imágenes. Esto podría implicar técnicas como la regresión logística, los árboles de decisión y las máquinas de vectores de soporte.

Finalmente, en la etapa de evaluación, el objetivo es evaluar la precisión y la relevancia de los modelos, y seleccionar el mejor modelo para la interpretación y la presentación de los resultados.
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

<strong> Requisitos </strong>

```{r message= FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(repos = list(CRAN="http://cran.rstudio.com/"))
if (!require('cluster')) install.packages('cluster')
if (!require('Stat2Data')) install.packages('Stat2Data')
if (!require('ggpubr')) install.packages('ggpubr')
if (!require('ggplot2')) install.packages('ggplot2')
if (!require('formattable')) install.packages('formattable')
if (!require ('kableExtra')) install.packages('kableExtra')
if (!require ('corrplot')) install.packages('corrplot')
if (!require('fpc')) install.packages('fpc')
if (!require('crayon')) install.packages('crayon')
if (!require('dbscan')) install.packages('dbscan')
if (!require('tidyverse')) install.packages('tidyverse')
if (!require('opticskxi')) install.packages('opticskxi', force=TRUE)
if (!require('GGally')) install.packages("GGally")
if (!require('lares')) install.packages("lares")
if (!require('caret')) install.packages("caret")
if (!require('rrcov')) install.packages("rrcov")
if (!require('gt')) install.packages("gt")
if (!require('c50')) install.packages('c50',  repos='http://cran.us.r-project.org', dependencies = T)
library(C50)
library(gt)
library(rrcov)
library(caret)
library(lares)
library(GGally)
library(opticskxi)
library(dbscan)
library(fpc)
library(kableExtra)
library(corrplot)
library(formattable)
library(ggpubr)
library(Stat2Data)
library(RColorBrewer)
library(Stat2Data)
library(cluster)
library(ggplot2)
library(plyr)
library(crayon)
library(tidyverse)
library(grid)
```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

## Análisis Exploratorio de Datos{.headers}

### Carga de datos{.headers}

Cargamos los datos del archivo csv wdbc.data descargado de (https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) y se crea el dataframe cancer_df

```{r message= FALSE, warning=FALSE}

# read original data Main DF cancer_df
cancer_df <- read.csv('wdbc.data', header = FALSE, col.names = c('id',	'diagnosis',	'radius_mean',	'texture_mean',	'perimeter_mean',	'area_mean',	'smoothness_mean',	'compactness_mean',	'concavity_mean',	'concave points_mean',	'symmetry_mean',	'fractal_dimension_mean',	'radius_se',	'texture_se',	'perimeter_se',	'area_se',	'smoothness_se',	'compactness_se',	'concavity_se',	'concave points_se',	'symmetry_se',	'fractal_dimension_se',	'radius_worst',	'texture_worst',	'perimeter_worst',	'area_worst',	'smoothness_worst',	'compactness_worst',	'concavity_worst',	'concave points_worst',	'symmetry_worst',	'fractal_dimension_worst'))

```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

### Resumen de los Datos{.headers}

En esta sección se presenta tantos en tablas como en gráficos la estructura del conjunto de datos.

```{r message= FALSE, warning=FALSE}

# Check first ten rows for preview
kable(cancer_df[0:10,],caption="<strong>Dataset Preview</strong>") %>% kable_classic(full_width=F, html_font = "Cambria") %>%kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive","bordered"),position = "left", font_size = 10) %>% row_spec(0,bold = TRUE, align = "c")

# Let's see data structure in botj summary tables and plot
options("lares.palette" =lares_pal("simple"))
df_str(cancer_df, return = "plot")

# Summary Stats for data
summary1 <- data.frame(unclass(summary(cancer_df[,0:10])),check.names = FALSE)
summary2 <- data.frame(unclass(summary(cancer_df[,11:20])),check.names = FALSE)
summary3 <- data.frame(unclass(summary(cancer_df[,21:31])),check.names = FALSE)

kable(summary1, caption = "<strong>Summary 1 Stats</strong>") %>% kable_classic(full_width=F, html_font = "Cambria") %>%kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive","bordered"),position = "left",font_size = 10) %>% row_spec(0,bold = TRUE, align = "c")

kable(summary2, caption = "<strong>Summary 2 Stats</strong>") %>% kable_classic( full_width=F, html_font = "Cambria") %>%kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive","bordered"),position = "left",font_size = 10)  %>% row_spec(0,bold = TRUE, align = "c")

kable(summary3, caption = "<strong>Summary 3 Stats</strong>") %>% kable_classic(full_width=F, html_font = "Cambria") %>%kable_styling(bootstrap_options = c("striped", "hover", "condensed","responsive","bordered"),position = "left",font_size = 10) %>% row_spec(0,bold = TRUE, align = "c") 
```

Podemos ver que no hay valores en blanco ni inváidos en dataset, la columna "diagnosis" toma valores binarios de maligno "M" o benigno "B" está se usará para validar en la próxima etapa del proyecto para validar los distintos modelos de clasificación o regresión que sea pertinente evaluar.

En la sección de discretización se tomará decisión de que variables discretizar y tener así variables categóricas.
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

### Comprobación de valores inválidos{.headers}

Igualmente para verificar cumplimos el requisito de verificar por valores inválidos NaN:

```{r message= FALSE, warning=FALSE}

# Check for NaN values in the dataframe
nan_values <- apply(cancer_df, 2, function(x) any(is.nan(x)))

# Display columns with NaN values
cols_with_nan <- names(cancer_df)[nan_values]
print(paste("Number of NaN values is", length(cols_with_nan)))

```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

### Exploración de variables{.headers}

En esta sección veremos la distribución de las distintas variables, al ser un dataset con 31 variables númericas en estas sección para facilitar los estudios de distribución y correlación seleccionaremos de momento las que tengan una correlación significativa aunque para los estudios de PCA y SVD se tomará en cuenta todo el dataset.


```{r message= FALSE, warning=FALSE}
# Let's see the top 10 variables most correlated to diagnosis variable with a correlation over 0.6

cancer_df %>% corr_var(diagnosis, ceiling = 60, top = 10, subtitle = NA, method ='pearson')+ggtitle('Top 10 variables correlacionadas con la variable diagnosis', subtitle = "")+scale_fill_manual(values=c('#66c2a5','#fc8d62'))+
        theme(legend.title = element_blank(),
        plot.title = element_text(size = 14, face = "bold"),
        panel.background = element_rect(fill = "#f6f1eb", 
                                        colour = "#f6f1eb", 
                                        size = 0.5, linetype = "solid"))
```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

Veamos la correlación y distribución a pares bivariables de las primeras seis variables:

```{r message= FALSE, warning=FALSE}
ggpairs(cancer_df,columns = c('diagnosis',	'concave.points_worst',	'perimeter_worst',	'concave.points_mean'), mapping = aes(color=cancer_df$diagnosis))+ scale_fill_manual(values=c('#66c2a5','#fc8d62'))+scale_colour_manual(values=c('#66c2a5','#fc8d62'))+theme(legend.title = element_blank(),
        panel.background = element_rect(fill = "#f6f1eb", 
                                        colour = "#f6f1eb", 
                                        size = 0.5, linetype = "solid"))

ggpairs(cancer_df,columns = c('diagnosis',	'radius_worst',	'perimeter_mean',	'area_worst'), mapping = aes(color=cancer_df$diagnosis))+ scale_fill_manual(values=c('#66c2a5','#fc8d62'))+scale_colour_manual(values=c('#66c2a5','#fc8d62'))+theme(legend.title = element_blank(),
        panel.background = element_rect(fill = "#f6f1eb", 
                                        colour = "#f6f1eb", 
                                        size = 0.5, linetype = "solid"))
```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

Con esto nos podemos dar una idea de las variables más importantes para el diagnostico correcto de usando los datos de todas formas debemos comparar con lo que obtendremos del estudio de PCA y SVD y ver si se corresponde.

Otra visualización importante del paquete lares que podemos utilizar es la distribución y proporciones:

```{r message= FALSE, warning=FALSE}
options("lares.palette" = c("#66c2a5" = "black", "#fc8d62" = 'white'))
cancer_df %>% distr(diagnosis, concave.points_worst, breaks = 5)+theme(axis.text.x = element_text(size=10, angle=45))
cancer_df %>% distr(diagnosis, perimeter_worst, breaks = 5)+theme(axis.text.x = element_text(size=10, angle=45))
cancer_df %>% distr(diagnosis, concave.points_mean, breaks = 5)+theme(axis.text.x = element_text(size=10, angle=45))
cancer_df %>% distr(diagnosis, radius_worst, breaks = 5)+theme(axis.text.x = element_text(size=10, angle=45))
cancer_df %>% distr(diagnosis, perimeter_mean, breaks = 5)+theme(axis.text.x = element_text(size=10, angle=45))
cancer_df %>% distr(diagnosis, area_worst, breaks = 5)+theme(axis.text.x = element_text(size=10, angle=45))

```
De forma general se puede observar como unas variables mejor que otras clasifican el diagnostico en los dos grupos. También de esta herramienta vemos como podemos discretizar ciertas variables en este caso usamos 5 intervalos.
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

### Identificación de outliers{.headers}

```{r message= FALSE, warning=FALSE}

# let's scale the dataset
df_scaled<- scale(cancer_df[,3:32])
df_scaled=as.data.frame(df_scaled)


# Convert to long format
df_long <- df_scaled %>%
  pivot_longer(
    everything(), 
    names_to = "variable", 
    values_to = "value"
  )

colourCount = length(unique(df_long$variable))
getPalette = colorRampPalette(brewer.pal(9, "Set1"))

# Var boxplots
ggplot(df_long, aes(x = variable, y = value, fill =variable)) +
  geom_boxplot() +
  labs(title = "Boxplots & Outliers", x = "Variable", y = "")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.title = element_blank(),
        legend.position ='none', 
        panel.background = element_rect(fill = "#f6f1eb", 
                                        colour = "#f6f1eb", 
                                        size = 0.5, linetype = "solid"))
```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

## Discretización {.headers}

Para discretizar las variables usaremos el método cut tomaremos radius_mean y area_worst en 5 categorías

```{r message= FALSE, warning=FALSE}
cancer_df$radius_cat <- cut(cancer_df$radius_mean, breaks = 5, labels = c('tiny', 'small', 'normal', 'medium','large'))

cancer_df$area_worst_cat <- cut(cancer_df$area_worst, breaks = 5, labels = c('tiny', 'small', 'normal', 'medium','large'))

cancer_df[0:10, c("radius_mean", "radius_cat","area_worst","area_worst_cat")]     

```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

Veamos ahora la estructura del dataset:

```{r message= FALSE, warning=FALSE}
options("lares.palette" =lares_pal("simple"))
df_str(cancer_df, return = "plot")
```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

## PCA {.headers}

Aplicaremos PCA (Principal Component Analysis) y evaluaremos cummulative proporpotion and proportion of variance de los componentes para ver los componentes que mejor describen los datos para hacer una reducción de la dimensionalidad

```{r message= FALSE, warning=FALSE}
pca_result <- prcomp(df_scaled)

summary(pca_result)

biplot(pca_result)
```

Se puede observar que hasta el componente 15 ya representa una cumulative proportion del 98% por lo que se puede reducir la dimensionalidad.
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

## SVD {.headers}
Esta sección aplicaremos el métdo SVD (Singular Value Decomposition)
```{r message= FALSE, warning=FALSE}
# SVD
svd_result <- svd(df_scaled)

singular_values <- svd_result$d

# Square of singular values
singular_values_squared <- singular_values^2

# Total variance
total_variance <- sum(singular_values_squared)

# Proportion of variance explained by each component
explained_variance <- singular_values_squared / total_variance

# Print the explained variance
print(explained_variance)

d <- svd_result$d
u <- svd_result$u
v <- svd_result$v

# First two components
svd_1 <- svd_result$u[,1] * svd_result$d[1]
svd_2 <- svd_result$u[,2] * svd_result$d[2]

# Dataframe for plot
df_svd <- data.frame(svd_1 = svd_1, svd_2 = svd_2)

df_svd$diagnosis <- cancer_df$diagnosis

ggplot(df_svd, aes(x = svd_1, y = svd_2, color = diagnosis)) +
  geom_point() +
  labs(title = "SVD - Primeros dos componentes singulares",
       x = "Primer componente singular",
       y = "Segundo componente singular") +
  theme_minimal()
```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

******
# Práctica 2 {.headers} 
******

## Modelo No Supervisado {.headers} 

Para el modelo no supervisado basado en distancia utilizaremos K-Medoids (PAM), como en principio debemos partir de que no conocemos el número de grupos o clusters a clasificar nuestros datos, vamos a utilizar el método de análisis de la silueta.

### Silhouette analysis of k-medoids clustering {.headers} 

```{r message= FALSE, warning=FALSE}
# Set the range of number of clusters to consider
library(cluster)
library(factoextra)

set.seed(7)

# Set the desired number of clusters
k <- 5

# Perform PAM clustering
pam_result <- pam(df_scaled, k = k, diss = TRUE)

# Use fviz_nbclust() to determine the optimal number of clusters
nbclust_result <- fviz_nbclust(df_scaled, pam, method = "silhouette")

# Plot the result
print(nbclust_result)

```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>


Se puede concluir que el número óptimo de clusters es dos, el método de análisis de la Silueta el punto con mayor promedio de ancho de silueta representa el número óptimo de clusters que es dos.

### Modelo k-medoids con métrica de distancia "euclidean" {.headers} 

Como primer modelo No supervisado haremos la clasificación con K-medois utilizando la métrica de distancia "euclidean" que es la métrica por defecto.

$$
\scriptsize \text{Donde la distancia entre dos puntos se calcula:}\\
\scriptsize d((x_1,x_2),(y_1,y_2)) = \scriptsize\sqrt{{(x_2 - x_1)^2 + (y_2 - y_1)^2}}
$$

Veamos graficamente la classificación que hacer el modelo comparada con la clasificación real utilizando las dos variables mas correlacionadas concave.points_worst y perimeter_worst:


```{r message= FALSE, warning=FALSE}

library(cluster)
library(factoextra)
library(ggplot2)
library(ggpubr)

set.seed(7)

# Compute the distance matrix using the Euclidean distance metric
distance_matrix <- dist(df_scaled, method = "euclidean")

# Perform k-medoids clustering
fit2 <- pam(distance_matrix, k = 2)

y_cluster2 <- fit2$clustering

plot15 <- ggplot(cancer_df, aes(x = concave.points_worst, y = perimeter_worst, fill = diagnosis)) +
  geom_point(color = "black", shape = 21, size = 3) +
  scale_fill_manual(values = c("#66c2a5", "#fc8d62"),
                    labels = c("Benign", "Malignant")) +
  theme(legend.title = element_blank(),
        plot.title = element_text(size = 10, face = "bold"),
        panel.background = element_rect(fill = "#f6f1eb", 
                                        colour = "#f6f1eb", 
                                        size = 0.5, linetype = "solid")) +
  ggtitle("Real Classification")

# Add the cluster assignments to the original dataframe
cancer_df1 <- cancer_df
cancer_df1$Cluster <- y_cluster2

# Create a scatter plot with ggplot2
plot16 <- ggplot(cancer_df1, aes(x = concave.points_worst, y = perimeter_worst, fill = factor(-Cluster))) +
  geom_point(color = "black", shape = 21, size = 3) +
  scale_fill_manual(values = c("#66c2a5", "#fc8d62"),
                    labels = c("Benign", "Malignant")) +
  labs(x = "concave.points_worst", y = "perimeter_worst", color = "Cluster") +
  ggtitle("K-medoids Clustering (k = 2)") +
  theme(legend.title = element_blank(),
        plot.title = element_text(size = 10, face = "bold"),
        panel.background = element_rect(fill = "#f6f1eb", 
                                        colour = "#f6f1eb", 
                                        size = 0.5, linetype = "solid"))

figure_4 <- ggarrange(plot15 + rremove("xlab"), plot16,
                      ncol = 1, nrow = 2,
                      common.legend = TRUE,
                      align = 'hv',
                      legend = "bottom")

annotate_figure(figure_4, top = text_grob('Comparison: Real Classification vs K-medoids/Euclidean\nVariable: concave.points_worst -- perimeter_worst',
                                          color = "black", 
                                          face = "bold", size = 10))


```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

### Evaluación del Modelo k-medoids con métrica de distancia "euclidean" {.headers} 

En esta sección evaluaremos el Modelo k-means con la métrica de de distancia euclidiana, para esto usando el paquete caret calcularemos la matriz de confusión y las siguiente métricas de evaluación:

$$
\scriptsize \text {Confusion Matrix}\\
\begin{array}{cc|c}
 & \scriptsize \text {Predicción Negative} & \scriptsize \text{Predicción Positive}\\
\hline
\scriptsize \text{Valor Real Negative} & \scriptsize TN & \scriptsize FP \\
\scriptsize \text{Valor Real Positive} & \scriptsize FN & \scriptsize TP \\
\end{array}
$$

$$
\scriptsize \text{Positive Predicted Value (Precisión)} = \frac{{\scriptsize \text{True Positives}}}{{\scriptsize \text{True Positives} + \scriptsize \text{False Positives}}}
$$


$$
\scriptsize \text{Accuracy (Exactitud)} = \frac{{\scriptsize \text{Number of Correct Predictions}}}{{\scriptsize \text{Total Number of Predictions}}}
$$

$$
\scriptsize \text{Sensitivity (Sensibilidad)} = \frac{{\scriptsize \text{True Positives}}}{{\scriptsize \text{True Positives} + \scriptsize \text{False Negatives}}}
$$

$$
\scriptsize \text{F-measure} = 2 \times \frac{{\scriptsize \text{Precisión} \times \scriptsize \text{Sensibilidad}}}{{\scriptsize \text{Precisión} + \scriptsize \text{Sensibilidad}}}
$$
**Referencia :** *"Modelos no supervisados" PID_00284572 Author: Jordi Gironés Roig*

```{r message= FALSE, warning=FALSE}

# Create label column in the dataframe to compare with the actual diagnosis
for (i in 1:length(cancer_df1$diagnosis)) {
  if (cancer_df1$Cluster[i] == 1) {
    cancer_df1$label[i] <- "M"
  } else {
    cancer_df1$label[i] <- "B"
  }
}

# Using caret package for the evaluation

# Convert the diagnosis and label columns to factors with the same levels
cancer_df1$diagnosis <- factor(cancer_df1$diagnosis, levels = c("B", "M"))
cancer_df1$label <- factor(cancer_df1$label, levels = c("B", "M"))

# Create a confusion matrix object
confusion_obj1 <- confusionMatrix(cancer_df1$label, cancer_df1$diagnosis)

# Print the formatted confusion matrix and performance statistics
cat("Matriz de confusión para el Modelo Kmedoids-Euclidean\n\n")
print(confusion_obj1)

# Save the differente metrics to compare later
kmedoids_model1_precision <- confusion_obj1$byClass["Pos Pred Value"]
kmedoids_model1_accuracy <- confusion_obj1$overall['Accuracy']
kmedoids_model1_sensitivity <- confusion_obj1$byClass["Sensitivity"]
kmedoids_model1_fmeasure <- confusion_obj1$byClass["F1"]

```

**Model k-medoids con métrica de distancia "euclidean"**<br><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Podemos ver que el modelo tiene:<br><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Precisión: **&nbsp;&nbsp;`r round(kmedoids_model1_precision,digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Exactitud: **`r round(kmedoids_model1_accuracy, digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Sensibilidad: **&nbsp;&nbsp;`r round(kmedoids_model1_sensitivity, digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**F-Measure: **&nbsp;&nbsp;`r round(kmedoids_model1_fmeasure, digits=4)`<br>

<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

### Modelo k-medoids con métrica de distancia "Manhattan" {.headers} 

La métrica de distancia Manhattan:

$$
\displaystyle \vert u-v\vert = \sum_{i=1}^n \vert u_i-v_i\vert
$$
```{r message= FALSE, warning=FALSE}

library(cluster)
library(factoextra)
library(ggplot2)
library(ggpubr)

set.seed(7)

# Compute the distance matrix using the Euclidean distance metric
distance_matrix <- dist(df_scaled, method = "manhattan")

# Perform k-medoids clustering
fit2 <- pam(distance_matrix, k = 2)

y_cluster2 <- fit2$clustering

plot15 <- ggplot(cancer_df, aes(x = concave.points_worst, y = perimeter_worst, fill = diagnosis)) +
  geom_point(color = "black", shape = 21, size = 3) +
  scale_fill_manual(values = c("#66c2a5", "#fc8d62"),
                    labels = c("Benign", "Malignant")) +
  theme(legend.title = element_blank(),
        plot.title = element_text(size = 10, face = "bold"),
        panel.background = element_rect(fill = "#f6f1eb", 
                                        colour = "#f6f1eb", 
                                        size = 0.5, linetype = "solid")) +
  ggtitle("Real Classification")

# Add the cluster assignments to the original dataframe
cancer_df2 <- cancer_df
cancer_df2$Cluster <- y_cluster2

# Create a scatter plot with ggplot2
plot16 <- ggplot(cancer_df2, aes(x = concave.points_worst, y = perimeter_worst, fill = factor(-Cluster))) +
  geom_point(color = "black", shape = 21, size = 3) +
  scale_fill_manual(values = c("#66c2a5", "#fc8d62"),
                    labels = c("Benign", "Malignant")) +
  labs(x = "concave.points_worst", y = "perimeter_worst", color = "Cluster") +
  ggtitle("K-medoids Clustering (k = 2)") +
  theme(legend.title = element_blank(),
        plot.title = element_text(size = 10, face = "bold"),
        panel.background = element_rect(fill = "#f6f1eb", 
                                        colour = "#f6f1eb", 
                                        size = 0.5, linetype = "solid"))

figure_4 <- ggarrange(plot15 + rremove("xlab"), plot16,
                      ncol = 1, nrow = 2,
                      common.legend = TRUE,
                      align = 'hv',
                      legend = "bottom")

annotate_figure(figure_4, top = text_grob('Comparison: Real Classification vs K-medoids/Mahattan\nVariable: concave.points_worst -- perimeter_worst',
                                          color = "black", 
                                          face = "bold", size = 10))

```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>


### Evaluación del Modelo k-medoids con métrica de distancia "manhattan" {.headers} 

```{r message= FALSE, warning=FALSE}


# Create label column in the dataframe to compare with the actual diagnosis
for (i in 1:length(cancer_df2$diagnosis)) {
  if (cancer_df2$Cluster[i] == 1) {
    cancer_df2$label[i] <- "M"
  } else {
    cancer_df2$label[i] <- "B"
  }
}

# Using caret package for the evaluation

# Convert the diagnosis and label columns to factors with the same levels
cancer_df2$diagnosis <- factor(cancer_df2$diagnosis, levels = c("B", "M"))
cancer_df2$label <- factor(cancer_df2$label, levels = c("B", "M"))

# Create a confusion matrix object
confusion_obj2 <- confusionMatrix(cancer_df2$label, cancer_df2$diagnosis)

# Print the formatted confusion matrix and performance statistics
cat("Matriz de confusión para el Modelo Kmedoids-Manhattan\n\n")
print(confusion_obj2)

# Save the differente metrics to compare later
kmedoids_model2_precision <- confusion_obj2$byClass["Pos Pred Value"]
kmedoids_model2_accuracy <- confusion_obj2$overall['Accuracy']
kmedoids_model2_sensitivity <- confusion_obj2$byClass["Sensitivity"]
kmedoids_model2_fmeasure <- confusion_obj2$byClass["F1"]
```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

### Comparación de los Modelos No Supervisados con dos métricas de distancia diferentes {.headers} 


```{r message= FALSE, warning=FALSE}

# Create a data frame with the evaluation metrics

metrics <- data.frame(
  Model = c("Model1/Euclidean", "Model2/Manhattan"),
  Precision = c(kmedoids_model1_precision, kmedoids_model2_precision),
  Accuracy = c(kmedoids_model1_accuracy, kmedoids_model2_accuracy),
  Sensitivity = c(kmedoids_model1_sensitivity, kmedoids_model2_sensitivity),
  F_measure = c(kmedoids_model1_fmeasure, kmedoids_model2_fmeasure),
  stringsAsFactors = FALSE
)
# Round the numbers to two decimal places in the metrics dataframe
metrics$Precision <- round(metrics$Precision, 2)
metrics$Accuracy <- round(metrics$Accuracy, 2)
metrics$Sensitivity <- round(metrics$Sensitivity, 2)
metrics$F_measure <- round(metrics$F_measure, 2)

# Calculate the percentage difference of each metric based on the existing values in the metrics dataframe
metrics_diff <- data.frame(
  Model = "Difference %",
  Precision = round((metrics$Precision[2] - metrics$Precision[1]) / metrics$Precision[1] * 100, 2),
  Accuracy = round((metrics$Accuracy[2] - metrics$Accuracy[1]) / metrics$Accuracy[1] * 100, 2),
  Sensitivity = round((metrics$Sensitivity[2] - metrics$Sensitivity[1]) / metrics$Sensitivity[1] * 100, 2),
  F_measure = round((metrics$F_measure[2] - metrics$F_measure[1]) / metrics$F_measure[1] * 100, 2),
  stringsAsFactors = FALSE
)

# Append the difference row to the metrics data frame
metrics <- rbind(metrics, metrics_diff)

styled_table <- kable(metrics, caption = "<strong>Comparación del modelo No Supervisado con métricas diferentes</strong>") %>%
  kable_classic(full_width = FALSE, html_font = "Cambria") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), position = "left", font_size = 10)%>%
  row_spec(0, bold = TRUE, align = "c") %>%
  row_spec(nrow(metrics), bold = TRUE, background = "lightgray")

styled_table





```

Se puede observar que ambos modelos hacen un trabajo de clasificación bastante bueno con los dos clusteres esperados. Sin embargo comparando las mediciones de la evaluación se ve que en este caso el modelo PAM se comporta mejor con la métrica de distancia Manhattan esto depende mucho del tipo de datos y como se agrupan.

<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

##  Modelo Clasificador con DBSCAN OPTICS {.headers} 

En este apartado utilizaremos los algoritmos DBSCAN OPTICS para la clasificación de nuestro dataset.

###  Modelo DBSCAN {.headers} 

```{r message= FALSE, warning=FALSE}
library(dbscan)
library(cluster)
library(factoextra)

# Set the range of epsilon values to consider
eps_values <- seq(0.1, 10, by = 0.1)

# Initialize vectors to store evaluation results
silhouette_scores <- vector("numeric", length = length(eps_values))
num_outliers <- vector("numeric", length = length(eps_values))

# Perform DBSCAN for different epsilon values
for (i in 1:length(eps_values)) {
  eps <- eps_values[i]
  
  # Apply DBSCAN
  dbscan_result <- dbscan(df_scaled, eps = eps, minPts = 10)
  
  # Check if valid clusters are present
  if (max(dbscan_result$cluster) > 0) {
    # Calculate the silhouette score
    silhouette_scores[i] <- mean(silhouette(dbscan_result$cluster, dist(df_scaled)))
  } else {
    # If no valid clusters, assign NA to silhouette score
    silhouette_scores[i] <- NA
  }
  
  # Count the number of outliers (noise points)
  num_outliers[i] <- sum(dbscan_result$cluster == 0)
}

# Find the index of the maximum silhouette score
max_silhouette_index <- which.max(silhouette_scores)
max_silhouette_eps <- eps_values[max_silhouette_index]
max_silhouette_score <- silhouette_scores[max_silhouette_index]

# Plot the evaluation results
plot(eps_values, silhouette_scores, type = "l",
     xlab = "Epsilon (eps)", ylab = "Silhouette Score",
     main = "DBSCAN: Silhouette Score vs. Epsilon")
points(max_silhouette_eps, max_silhouette_score, col = "red", pch = 16)
text(max_silhouette_eps, max_silhouette_score, 
     labels = paste("Max Silhouette Score:\nEpsilon =", round(max_silhouette_eps, 2)), 
     pos = 1)

plot(eps_values, num_outliers, type = "l",
     xlab = "Epsilon (eps)", ylab = "Number of Outliers",
     main = "DBSCAN: Number of Outliers vs. Epsilon")


```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

Como primer paso para buscar donde el algoritmo DBSCAN tendrá la mejor clasificación debemos buscar el valor de epsilon ótimo para esto hacemos las gráficas de Silhoute Score vs Epsilon y Outliers vs Epsilon la idea es buscar un balance entre el valor de Epsilon da el mayor Silhoute Score y un menor número de outliers. De las dos gráficas anteriores y escogeremos el valor de 2.65

```{r message= FALSE, warning=FALSE}
library(cluster)
library(factoextra)
library(ggplot2)
library(ggpubr)

set.seed(7)

# Perform DBSCAN clustering with epsilon = 2.65
dbscan_result <- dbscan(df_scaled, eps = 2.65, minPts = 10)

y_cluster_dbscan <- dbscan_result$cluster

plot17 <- ggplot(cancer_df, aes(x = concave.points_worst, y = perimeter_worst, fill = diagnosis)) +
  geom_point(color = "black", shape = 21, size = 3) +
  scale_fill_manual(values = c("#66c2a5", "#fc8d62"),
                    labels = c("Benign", "Malignant")) +
  theme(legend.title = element_blank(),
        plot.title = element_text(size = 10, face = "bold"),
        panel.background = element_rect(fill = "#f6f1eb", 
                                        colour = "#f6f1eb", 
                                        size = 0.5, linetype = "solid")) +
  ggtitle("Real Classification")

# Add the cluster assignments to the original dataframe
cancer_df_dbscan <- cancer_df
cancer_df_dbscan$Cluster <- -y_cluster_dbscan

# Create a scatter plot with ggplot2
plot18 <- ggplot(cancer_df_dbscan, aes(x = concave.points_worst, y = perimeter_worst, fill = factor(Cluster))) +
  geom_point(color = "black", shape = 21, size = 3) +
  scale_fill_manual(values = c("#66c2a5", "#fc8d62", "#8da0cb", "#e78ac3", "#a6d854", "#ffd92f"),
                    labels = c("Noise", "Cluster 1", "Cluster 2", "Cluster 3", "Cluster 4", "Cluster 5")) +
  labs(x = "concave.points_worst", y = "perimeter_worst", color = "Cluster") +
  ggtitle("DBSCAN Clustering (epsilon = 2.5)") +
  theme(legend.title = element_blank(),
        plot.title = element_text(size = 10, face = "bold"),
        panel.background = element_rect(fill = "#f6f1eb", 
                                        colour = "#f6f1eb", 
                                        size = 0.5, linetype = "solid"))

figure_5 <- ggarrange(plot17 + rremove("xlab"), plot18,
                      ncol = 1, nrow = 2,
                      common.legend = TRUE,
                      align = 'hv',
                      legend = "bottom")

annotate_figure(figure_5, top = text_grob('Comparison: Real Classification vs DBSCAN/Epsilon=2.65\nVariable: concave.points_worst -- perimeter_worst',
                                          color = "black", 
                                          face = "bold", size = 10))
```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>


```{r message= FALSE, warning=FALSE}
# Create label column in the dataframe to compare with the actual diagnosis
for (i in 1:length(cancer_df_dbscan$Cluster)) {
  if (cancer_df_dbscan$Cluster[i] == -1) {
    cancer_df_dbscan$label[i] <- "B"
  } else {
    cancer_df_dbscan$label[i] <- "M"
  }
}

# Using caret package for the evaluation

# Convert the diagnosis and label columns to factors with the same levels
cancer_df_dbscan$diagnosis <- factor(cancer_df_dbscan$diagnosis, levels = c("B", "M"))
cancer_df_dbscan$label <- factor(cancer_df_dbscan$label, levels = c("B", "M"))

# Create a confusion matrix object
confusion_obj_dbscan <- confusionMatrix(cancer_df_dbscan$label, cancer_df_dbscan$diagnosis)

# Print the formatted confusion matrix and performance statistics
cat("Confusion Matrix for DBSCAN Clustering (epsilon = 2.65)\n\n")
print(confusion_obj_dbscan)

# Save the different metrics to compare later
dbscan_model_precision <- confusion_obj_dbscan$byClass["Pos Pred Value"]
dbscan_model_accuracy <- confusion_obj_dbscan$overall['Accuracy']
dbscan_model_sensitivity <- confusion_obj_dbscan$byClass["Sensitivity"]
dbscan_model_fmeasure <- confusion_obj_dbscan$byClass["F1"]

```

**Model DBSCAN con epsilón 2,65 y miPts 10**<br><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Podemos ver que el modelo tiene:<br><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Precisión: **&nbsp;&nbsp;`r round(dbscan_model_precision,digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Exactitud: **`r round(dbscan_model_accuracy, digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Sensibilidad: **&nbsp;&nbsp;`r round(dbscan_model_sensitivity, digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**F-Measure: **&nbsp;&nbsp;`r round(dbscan_model_fmeasure, digits=4)`<br>

Podemos ver como el modelo DBSCAN se comporta peor que los modelos anteriores de K-mediods (PAM) por la naturaleza del dataset y sumado a la complejidad de afinar los párametros de momento podemos decir que para está clasificación binaria los clasificadores como k-means o k-mediods son bastante efectivos en contra de otros más complejos como el DBSCAN.

<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

##  Modelo Supervisado Arbol de clasificación {.headers}

### Preparación de los datos {.headers}

Para la futura evaluación del árbol de decisión, es necesario dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba. El conjunto de entrenamiento es el subconjunto del conjunto original de datos utilizado para construir un primer modelo; y el conjunto de prueba, el subconjunto del conjunto original de datos utilizado para evaluar la calidad del modelo.

Lo más correcto será utilizar un conjunto de datos diferente del que utilizamos para construir el árbol, es decir, un conjunto diferente del de entrenamiento. No hay ninguna proporción fijada en este caso utilizaremos un 2/3 para el set de entrenamiento y un 1/3 para el test.


```{r message= FALSE, warning=FALSE}
set.seed(287)  # For reproducibility

# Remove the first two columns from the dataframe
X1 <- cancer_df %>% select(-c(1, 2))
y1 <- cancer_df$diagnosis

split_prop <- 3
indexes <- sample(1:nrow(cancer_df), size = floor(((split_prop - 1) / split_prop) * nrow(cancer_df)))
```
### Creación de los Modelos,calidad y extracción de reglas {.headers}

Se crea el árbol de decisión usando los datos de entrenamiento.

```{r message= FALSE, warning=FALSE}
set.seed(287)

trainX1 <- X1[indexes, ]
trainy1 <- y1[indexes]
testX1 <- X1[-indexes, ]
testy1 <- y1[-indexes]

trainy1 <-  as.factor(trainy1)
model <- C50::C5.0(trainX1, trainy1,rules=TRUE )
summary(model)

```

Se puede observar que para este modelo se crean 6 reglas de decisión y Errors muestra el número y porcentaje de casos mal clasificados en el subconjunto de entrenamiento. El árbol obtenido clasifica erróneamente sólo 3 de los 379 casos dados, una tasa de error del **0.8%**.

Dentro de las reglas podemos resaltar:

La **regla 1** que con los parámetros indicados abajo clasifica como “B” (Benigno) con una válidez del **98.6%**

**Rule 1**: (70, lift 1.6)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	concavity_mean <= 0.06155<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	compactness_se > 0.01597<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	->  class B  [0.986]<br>

La **regla 4** que con los parámetros indicados abajo clasifica como “M” (Maligno) con una válidez del **99.0%**

**Rule 4**: (70, lift 1.6)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	concave.points_mean > 0.0539
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	concave.points_se <= 0.01992
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  concave.points_worst > 0.1423
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	->  class M  [0.990]

<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

### Representación gráfica del Modelo de Arbol {.headers}

```{r message= FALSE, warning=FALSE}

model <- C50::C5.0(trainX1, trainy1)
plot(model,gp = gpar(fontsize = 8))

```
<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

### Validación del Modelo de Arbol {.headers}

En este apartado validaremos como en los otros casos las métrica del modelo en este caso con el set de datos reservado para el test.

```{r message= FALSE, warning=FALSE}

# Calculate performance metrics for the classification tree model
predicted_model <- predict(model, testX1, type = "class")

# Convert the predicted values to character
predicted_model <- as.character(predicted_model)

# Create a factor with the levels and testy1
predicted_model <- factor(predicted_model)
testy1 <- factor(testy1)

# Create a confusion matrix object
confusion_obj_tree <- confusionMatrix(predicted_model, testy1)

# Print the formatted confusion matrix
cat("Confusion Matrix for Classification Tree Model\n\n")
print(confusion_obj_tree)

# Save the different metrics to compare later
tree_model_precision <- confusion_obj_tree$byClass["Pos Pred Value"]
tree_model_accuracy <- confusion_obj_tree$overall["Accuracy"]
tree_model_sensitivity <- confusion_obj_tree$byClass["Sensitivity"]
tree_model_fmeasure <- confusion_obj_tree$byClass["F1"]

```

**Modelo de Arbol**<br><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Podemos ver que el modelo tiene:<br><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Precisión: **&nbsp;&nbsp;`r round(tree_model_precision,digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Exactitud: **`r round(tree_model_accuracy, digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Sensibilidad: **&nbsp;&nbsp;`r round(tree_model_sensitivity, digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**F-Measure: **&nbsp;&nbsp;`r round(tree_model_fmeasure, digits=4)`<br>

Se ve que el modelo de arbol clasifica los datos del test set bastante bien el modelo con una precisión del 91.47% bastante similar a la obtenida con los datos de entrenamiento lo que hace un modelo bastante consistente.

<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

##  Random Forest{.headers}

Como segundo modelo supervisado usaremos el random forest similar al classification tree  entrenamos el model con las misma proporcion del dataset y lo probamos con el test set y generamos la matriz de confusión.

```{r message= FALSE, warning=FALSE}
library(randomForest)

# Set the seed for reproducibility
set.seed(287)

# Split the data into training and testing sets
split_prop <- 3
indexes <- sample(1:nrow(cancer_df), size = floor(((split_prop - 1) / split_prop) * nrow(cancer_df)))

trainX1 <- X1[indexes, ]
trainy1 <- y1[indexes]
testX1 <- X1[-indexes, ]
testy1 <- y1[-indexes]

# Convert the target variable to a factor
trainy1 <- as.factor(trainy1)

# Train the Random Forest model
model_rf <- randomForest(trainX1, trainy1)

# Make predictions on the test set
predicted_rf <- predict(model_rf, testX1)

# Convert the predicted values to character and create factors
predicted_rf <- as.factor(as.character(predicted_rf))
testy1 <- as.factor(as.character(testy1))

# Create a confusion matrix object
confusion_obj_rf <- confusionMatrix(predicted_rf, testy1)

# Print the formatted confusion matrix
cat("Confusion Matrix for Random Forest Model\n")
print(confusion_obj_rf)

# Save the different metrics to compare later
rf_model_precision <- confusion_obj_rf$byClass["Pos Pred Value"]
rf_model_accuracy <- confusion_obj_rf$overall["Accuracy"]
rf_model_sensitivity <- confusion_obj_rf$byClass["Sensitivity"]
rf_model_fmeasure <- confusion_obj_rf$byClass["F1"]

```
**Modelo de Arbol**<br><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Podemos ver que el modelo tiene:<br><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Precisión: **&nbsp;&nbsp;`r round(rf_model_precision,digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Exactitud: **`r round(rf_model_accuracy, digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Sensibilidad: **&nbsp;&nbsp;`r round(rf_model_sensitivity, digits=4)`<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**F-Measure: **&nbsp;&nbsp;`r round(rf_model_fmeasure, digits=4)`<br>

Se ve que el modelo de arbol clasifica los datos del test set bastante bien el modelo con una precisión del 91.47% bastante similar a la obtenida con los datos de entrenamiento lo que hace un modelo bastante consistente.

<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>

##  Comparación y Conclusiones{.headers}

Primero vamos a crear una tabla con las métricas de los distintos modelos estudiados:

```{r message= FALSE, warning=FALSE}
# Create a data frame with the metrics for each model
metrics <- data.frame(
  Model = c("DBSCAN", "Classification Tree", "K-Medoids Model/Euclidean", "K-Medoids Model/Manhattan", "Random Forest"),
  Precision = c(dbscan_model_precision, tree_model_precision, kmedoids_model1_precision, kmedoids_model2_precision,rf_model_precision),
  Accuracy = c(dbscan_model_accuracy, tree_model_accuracy, kmedoids_model1_accuracy, kmedoids_model2_accuracy,rf_model_accuracy),
  Sensitivity = c(dbscan_model_sensitivity, tree_model_sensitivity, kmedoids_model1_sensitivity, kmedoids_model2_sensitivity,rf_model_sensitivity),
  F_measure = c(dbscan_model_fmeasure, tree_model_fmeasure, kmedoids_model1_fmeasure, kmedoids_model2_fmeasure,rf_model_fmeasure),
  stringsAsFactors = FALSE
)

# Round the numbers to two decimal places in the metrics dataframe
metrics$Precision <- round(metrics$Precision, 2)
metrics$Accuracy <- round(metrics$Accuracy, 2)
metrics$Sensitivity <- round(metrics$Sensitivity, 2)
metrics$F_measure <- round(metrics$F_measure, 2)

# Find the column index of the highest value in each column
highlight_cols <- apply(metrics[-1], 2, function(x) ifelse(x == max(x), "background-color: yellow", ""))

# Create a styled table using the kableExtra package
styled_table <- kable(metrics, caption = "<strong>Comparación de los modelos</strong>") %>%
  kable_classic(full_width = FALSE, html_font = "Cambria") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"), position = "left", font_size = 10) %>%
  row_spec(0, bold = TRUE, align = "c") %>%
  row_spec(nrow(metrics), bold = TRUE, background = "lightgray")

# Apply cell highlighting to each column based on the highest value
for (i in 2:ncol(metrics)) {
  styled_table <- styled_table %>%
    column_spec(i, color = ifelse(highlight_cols[[i - 1]] != "", "black", "inherit"),
                background = highlight_cols[[i - 1]])
}

styled_table

```

<br>Comparando los modelos aplicados a la clasificación del conjunto de datos de Cáncer de Mama de Wisconsin, podemos analizar su rendimiento en términos de precisión, exactitud, sensibilidad y F-measure. Los modelos considerados son DBSCAN (no supervisado), Árbol de Clasificación (supervisado), Modelo K-Medoids con distancia euclidiana (no supervisado), Modelo K-Medoids con distancia Manhattan (no supervisado) y Random Forest (supervisado).<br><br>

Al observar la métrica de precisión, que mide la proporción de casos positivos correctamente predichos, podemos observar que el Random Forest **(0.94)** tiene la mayor precisión. Esto indica que el Random Forest es más efectivo para identificar correctamente los casos malignos. Sin embargo, el Árbol de Clasificación **(0.91)** y el Modelo K-Medoids con distancia Manhattan **(0.94)** también demuestran una alta precisión).<br><br>

En cuanto a la exactitud, que mide la corrección general de las predicciones del modelo, el Random Forest **(0.94)** y el Modelo K-Medoids con distancia Manhattan **(0.94)** tienen la mayor exactitud. Estos modelos realizan las predicciones más precisas en general).<br><br>

En cuanto a la sensibilidad, que evalúa la capacidad del modelo para identificar correctamente los casos verdaderos positivos, el Random Forest **(0.98)** supera a los demás modelos. Tiene la sensibilidad más alta, lo que indica que puede identificar de manera efectiva la mayoría de los casos malignos. El Árbol de Clasificación **(0.97)** y ambos modelos K-Medoids **(0.95)** también muestran una sensibilidad sólida).<br><br>

F-measure combina la precisión y la sensibilidad en una sola métrica, lo que representa la efectividad general del modelo. Aquí, el Random Forest **(0.96)** alcanza la medida F más alta, lo que indica su rendimiento equilibrado tanto en precisión como en sensibilidad. El Árbol de Clasificación **(0.94)** y el Modelo K-Medoids con distancia Manhattan **(0.95)** también demuestran una buena F-measure).<br><br>

Considerando las limitaciones de estos modelos, es importante analizar las características del conjunto de datos y la tarea de clasificación. El conjunto de datos de Cáncer de Mama de Wisconsin implica clasificar los casos como benignos o malignos un problema de clasificación binaria).<br><br>

El uso de modelos no supervisados para la clasificación en este contexto plantea varios riesgos. DBSCAN, por ejemplo, se basa en agrupamiento basado en densidad y no considera las etiquetas de clase reales. Puede tener dificultades para clasificar correctamente las nuevas instancias y es más adecuado para la detección de anomalías en lugar de tareas explícitas de clasificación binaria, como el diagnóstico de cáncer).<br><br>

Del mismo modo, los modelos K-Medoids, aunque se basan en agrupamiento, pueden tener limitaciones para discriminar de manera efectiva entre casos benignos y malignos. La elección de la métrica de distancia (euclidiana o Manhattan) puede afectar el rendimiento del modelo, pero ambos modelos pueden no considerar toda la información disponible en los datos etiquetados).<br><br>
En contraste, los modelos supervisados como el Árbol de Clasificación y el Random Forest aprovechan los datos etiquetados para realizar predicciones informadas. Consideran la relación entre las características y las etiquetas de clase, lo que permite predicciones más precisas y confiables. Estos modelos pueden capturar patrones e interacciones complejas dentro del conjunto de datos, lo que conduce a un mejor rendimiento en tareas de clasificación).<br><br>

Sin embargo, es importante reconocer que todos los modelos tienen sus propias limitaciones. Se basan en la suposición de que las características de entrada son informativas y representativas de la variable objetivo. Las características inadecuadas o irrelevantes pueden afectar negativamente el rendimiento del modelo. Además, puede ocurrir el sobreajuste si los modelos son demasiado complejos o si el conjunto de datos es pequeño).<br><br>
Para mitigar los riesgos, es importante evaluar minuciosamente los modelos utilizando métricas de evaluación apropiadas, como la validación cruzada, y evaluar su rendimiento en conjuntos de prueba independientes. Además, se pueden aplicar técnicas de selección de características y métodos de preprocesamiento para mejorar el rendimiento del modelo).<br><br>
En conclusión, considerando el conjunto de datos y la tarea de clasificación proporcionados, el modelo de Bosque Aleatorio destaca como el mejor rendimiento en general en términos de precisión, exactitud, sensibilidad y F-measure. Los modelos supervisados como el Random Forest y el Árbol de Clasificación tienden a superar a los modelos no supervisados en este contexto debido a su capacidad para aprovechar los datos etiquetados y realizar predicciones informadas. Sin embargo, se deben tener en cuenta las características del conjunto de datos y aplicar técnicas de evaluación adecuadas para elegir el modelo más adecuado para la clasificación de distintos problemas).<br><br>

<a style="display: block; text-align: right;"href="#top"> ↑ Volver al inicio </a>
